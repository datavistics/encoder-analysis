{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6916b743-614c-458c-8bbe-0e0b3dc4265f",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "53c8bd6c-c878-4ba3-99a3-274caa76e703",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8bd913e5eeb14aa7bfa04b989f17fb99",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.svâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from huggingface_hub import login\n",
    "\n",
    "login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "24205295-ad1e-4e33-9f7e-87f872d666a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DATASET CONFIG\n",
    "DATASET='tyqiangz/multilingual-sentiments'\n",
    "MODEL='lxyuan/distilbert-base-multilingual-cased-sentiments-student'\n",
    "MIN_TOKENS=50\n",
    "MAX_TOKENS=512\n",
    "SAMPLES=10_000\n",
    "MAX_VUS = 2000\n",
    "TEXT_COLUMN='text'\n",
    "DATASET_PATH='data/dataset.json'\n",
    "K6_BIN = \"/usr/bin/k6\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8d29c264-21ad-4e69-9c1a-585cf867c297",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-01-24 09:41:20.090\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[36msrc.process_dataset\u001b[0m:\u001b[36msample_dataset\u001b[0m:\u001b[36m29\u001b[0m - \u001b[32m\u001b[1mSampled dataset down to 10000 samples\u001b[0m\n",
      "\u001b[32m2025-01-24 09:41:20.227\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[36msrc.process_dataset\u001b[0m:\u001b[36msave_dataset\u001b[0m:\u001b[36m42\u001b[0m - \u001b[32m\u001b[1mSaved dataset to data/dataset.json\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "from transformers import AutoTokenizer\n",
    "from src.process_dataset import tokenize_and_filter, sample_dataset, save_dataset\n",
    "\n",
    "dataset = load_dataset(DATASET, 'all', split='train')\n",
    "\n",
    "# Map numbers to text labels\n",
    "label_mapping = {0: 'positive', 1: 'neutral', 2: 'negative'}\n",
    "dataset = dataset.map(lambda example: {'label_text': label_mapping[example['label']]})\n",
    "\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL)\n",
    "\n",
    "dataset = tokenize_and_filter(dataset, tokenizer, text_column='text', num_proc=8)\n",
    "dataset = sample_dataset(dataset, n_samples=SAMPLES, min_tokens=MIN_TOKENS, max_tokens=MAX_TOKENS, seed=42)\n",
    "save_dataset(dataset.select_columns(['text', 'label_text']), DATASET_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "63763da5-eaef-4ce8-a7a9-83ffdb6911d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass, field, asdict\n",
    "from typing import Dict\n",
    "\n",
    "@dataclass\n",
    "class InstanceConfig:\n",
    "    repository: str\n",
    "    accelerator: str\n",
    "    instance_size: str\n",
    "    instance_type: str\n",
    "    custom_image: Dict[str, str]  # Dict of str -> str\n",
    "\n",
    "@dataclass\n",
    "class ImageConfig:\n",
    "    health_route: str = \"/health\"\n",
    "    url: str = \"michaelf34/infinity:0.0.75\"\n",
    "    env: Dict[str, str] = field(default_factory=lambda: {\n",
    "        \"INFINITY_PORT\": \"80\",\n",
    "        \"INFINITY_ENGINE\": \"torch\",\n",
    "        \"INFINITY_BATCH_SIZE\": \"16\",\n",
    "        \"INFINITY_DTYPE\": \"auto\",\n",
    "        \"INFINITY_EMBEDDING_DTYPE\": \"float32\",\n",
    "        \"INFINITY_POOLING_METHOD\": \"auto\",\n",
    "        \"INFINITY_COMPILE\": 'true',\n",
    "        \"INFINITY_BETTERTRANSFORMER\": 'true',\n",
    "        \"INFINITY_MODEL_ID\": \"/repository\"\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cf2734e8-4ac9-41cc-9654-e2bfe7b5f19d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_batch_size(batch_size: int) -> Dict[str, str]:\n",
    "    config = asdict(ImageConfig())\n",
    "    config['env'][\"INFINITY_BATCH_SIZE\"] = str(batch_size)\n",
    "    return config"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "199632b1-8a67-4c7c-9573-7465c011cbf4",
   "metadata": {},
   "source": [
    "# Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6ec56d04-0eb0-4065-ac86-d310a00ee2b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "instance_config_experiment_dicts = [\n",
    "    {\n",
    "        'accelerator': 'gpu',\n",
    "        'instance_size': 'x1',\n",
    "        'instance_type': 'nvidia-t4'\n",
    "    },\n",
    "    {\n",
    "        'accelerator': 'gpu',\n",
    "        'instance_size': 'x1',\n",
    "        'instance_type': 'nvidia-l4'\n",
    "    },\n",
    "]\n",
    "instance_config_experiments = [InstanceConfig(repository=MODEL, **ic_exp_dict, custom_image=None) for ic_exp_dict in instance_config_experiment_dicts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bff9d93e-cd85-413c-b05c-497fd387b61a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'health_route': '/health',\n",
       " 'url': 'michaelf34/infinity:0.0.75',\n",
       " 'env': {'INFINITY_PORT': '80',\n",
       "  'INFINITY_ENGINE': 'torch',\n",
       "  'INFINITY_BATCH_SIZE': '24',\n",
       "  'INFINITY_DTYPE': 'auto',\n",
       "  'INFINITY_EMBEDDING_DTYPE': 'float32',\n",
       "  'INFINITY_POOLING_METHOD': 'auto',\n",
       "  'INFINITY_COMPILE': 'true',\n",
       "  'INFINITY_BETTERTRANSFORMER': 'true',\n",
       "  'INFINITY_MODEL_ID': '/repository'}}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set_batch_size(24)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1ae77ff1-9e01-4837-8035-5d39257ef5d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mSignature:\u001b[0m \u001b[0mdeploy_endpoint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minstance_config\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
       "\u001b[0;31mDocstring:\u001b[0m\n",
       "Deploys or updates a Hugging Face inference endpoint.\n",
       "\n",
       "This function checks if an existing inference endpoint with the specified name exists.\n",
       "- If found, it updates the endpoint with the provided instance configuration.\n",
       "- If not found, it creates a new inference endpoint with the given parameters.\n",
       "\n",
       "Once the endpoint is updated or created, it waits until the endpoint is fully ready.\n",
       "\n",
       "Args:\n",
       "    instance_config (InstanceConfig): A dataclass containing instance configuration details,\n",
       "                                      such as accelerator type, vendor, region, and instance size.\n",
       "\n",
       "Returns:\n",
       "    InferenceEndpoint: The deployed Hugging Face inference endpoint object.\n",
       "\n",
       "Raises:\n",
       "    Exception: If the endpoint creation process fails.\n",
       "\u001b[0;31mFile:\u001b[0m      /data/src/deployment.py\n",
       "\u001b[0;31mType:\u001b[0m      function"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from src.deployment import deploy_endpoint\n",
    "?deploy_endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "64e8f4d4-cc7b-4414-9183-d84173ae1bf6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-01-24 09:41:27.840\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.deployment\u001b[0m:\u001b[36mdeploy_endpoint\u001b[0m:\u001b[36m83\u001b[0m - \u001b[1mCreating inference endpoint...\u001b[0m\n",
      "\u001b[32m2025-01-24 09:41:27.954\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.deployment\u001b[0m:\u001b[36mdeploy_endpoint\u001b[0m:\u001b[36m104\u001b[0m - \u001b[1mWaiting for endpoint to be ready...\u001b[0m\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'BATCH_SIZE'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 15\u001b[0m\n\u001b[1;32m     13\u001b[0m instance_config_experiment \u001b[38;5;241m=\u001b[39m copy\u001b[38;5;241m.\u001b[39mdeepcopy(og_instance_config_experiment)\n\u001b[1;32m     14\u001b[0m instance_config_experiment\u001b[38;5;241m.\u001b[39mcustom_image \u001b[38;5;241m=\u001b[39m set_batch_size(batch_size)\n\u001b[0;32m---> 15\u001b[0m endpoint \u001b[38;5;241m=\u001b[39m \u001b[43mdeploy_endpoint\u001b[49m\u001b[43m(\u001b[49m\u001b[43minstance_config_experiment\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     17\u001b[0m args_dict \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mdict\u001b[39m(\n\u001b[1;32m     18\u001b[0m     endpoint\u001b[38;5;241m=\u001b[39mendpoint,\n\u001b[1;32m     19\u001b[0m     total_requests\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10_000\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     23\u001b[0m     k6_bin\u001b[38;5;241m=\u001b[39mK6_BIN\n\u001b[1;32m     24\u001b[0m )\n\u001b[1;32m     26\u001b[0m optimal_vus(max_vus\u001b[38;5;241m=\u001b[39mMAX_VUS, args_dict\u001b[38;5;241m=\u001b[39margs_dict, start_vus\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m16\u001b[39m)\n",
      "File \u001b[0;32m/data/src/deployment.py:112\u001b[0m, in \u001b[0;36mdeploy_endpoint\u001b[0;34m(instance_config)\u001b[0m\n\u001b[1;32m    109\u001b[0m elapsed_minutes, elapsed_seconds \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mdivmod\u001b[39m(elapsed_time, \u001b[38;5;241m60\u001b[39m)\n\u001b[1;32m    111\u001b[0m hw_type \u001b[38;5;241m=\u001b[39m endpoint\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__dict__\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mraw\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcompute\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124minstanceType\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m--> 112\u001b[0m batch_size \u001b[38;5;241m=\u001b[39m \u001b[43mendpoint\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;18;43m__dict__\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mraw\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmodel\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43menv\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mBATCH_SIZE\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[1;32m    113\u001b[0m logger\u001b[38;5;241m.\u001b[39msuccess(\n\u001b[1;32m    114\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEndpoint created successfully: hw=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mhw_type\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;124mbs=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbatch_size\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    115\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTime taken: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mint\u001b[39m(elapsed_minutes)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124mm \u001b[39m\u001b[38;5;132;01m{\u001b[39;00melapsed_seconds\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124ms\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    116\u001b[0m )\n\u001b[1;32m    117\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m endpoint\n",
      "\u001b[0;31mKeyError\u001b[0m: 'BATCH_SIZE'"
     ]
    }
   ],
   "source": [
    "from src.k6 import call_k6, optimal_vus\n",
    "from pathlib import Path\n",
    "import copy\n",
    "from time import sleep\n",
    "\n",
    "template_file = \"classification-analysis.js.j2\"\n",
    "output_file = Path(\"./generated\").resolve()/\"classification-analysis.js\"\n",
    "\n",
    "batch_sizes = [16, 32, 64, 128, 256, 512, 1024]\n",
    "\n",
    "for og_instance_config_experiment in instance_config_experiments:\n",
    "    for batch_size in batch_sizes:\n",
    "        instance_config_experiment = copy.deepcopy(og_instance_config_experiment)\n",
    "        instance_config_experiment.custom_image = set_batch_size(batch_size)\n",
    "        endpoint = deploy_endpoint(instance_config_experiment)\n",
    "\n",
    "        args_dict = dict(\n",
    "            endpoint=endpoint,\n",
    "            total_requests=10_000,\n",
    "            template_file=template_file,\n",
    "            output_file=output_file,\n",
    "            dataset_path=DATASET_PATH,\n",
    "            k6_bin=K6_BIN\n",
    "        )\n",
    "        \n",
    "        optimal_vus(max_vus=MAX_VUS, args_dict=args_dict, start_vus=16)\n",
    "        endpoint.delete()\n",
    "        sleep(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77b49683-1652-4d10-b146-d22f311bfb62",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
